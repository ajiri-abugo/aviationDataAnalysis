# aviationDataAnalysis

ğŸ“Œ Project Overview

The Aviation Data Analysis Project is an end-to-end data engineering pipeline designed to help a travel agency become more profitable by analyzing aviation data. The pipeline collects, processes, stores, and visualizes key insights, such as busiest routes and ticket price trends.

ğŸ› ï¸ Technologies Used

Programming Languages: Python (ETL scripts, data cleaning)

Databases: MongoDB (Data Lake), PostgreSQL (Data Warehouse), MySQL (Data Quality Logs)

Orchestration: Airflow

Streaming: Kafka

Visualization: Google Looker

Other Tools: Docker (Containers), .env files for environment variables

ğŸ—‚ï¸ Project Structure

aviationDataAnalysis/
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ extract/
â”‚   â”‚   â””â”€â”€ api_scraper.py
â”‚   â”œâ”€â”€ load/
â”‚   â”‚   â””â”€â”€ airports_datalake.py
â”‚   â””â”€â”€ transform/
â”‚       â””â”€â”€ routes_cleaning.py
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ dbconnect.py
â”‚   â”œâ”€â”€ mongoconnect.py
â”‚   â””â”€â”€ mysqlconnect.py
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ data_quality.log
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md


ğŸ’¾ Data Pipeline Workflow

Data Ingestion: Collects real-time flight data from APIs using Kafka.

Data Cleaning: Applies tailored cleaning and validation functions.

Data Loading: Stores raw data in MongoDB and cleaned data in PostgreSQL.

Data Quality Checks: Logs issues (duplicates, missing values) into MySQL.

Data Visualization: Displays insights on Google Looker dashboards.

ğŸ“Š Key Datasets

Airport List: Contains airport codes, city, timezone, and country.

Airport Routes: Shows departure and arrival airports, state, and region.


ğŸš€ How to Run the Project

1. Set Up Environment
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

2. Configure .env File
Create a .env file with:
MONGO_URI=<your_mongo_uri>
POSTGRES_URI=<your_postgres_uri>
API_KEY=<your_api_key>

3. Start Kafka and MongoDB (if using Docker)
docker-compose up

4. Run ETL Scripts
python3 etl/extract/extract-countries.py
python3 etl/load/countries-datalake.py
python3 etl/load/airports_datalake.py

ğŸš§ Future Enhancements

Implement pipeline monitoring with Prometheus and Grafana

*Add schema enforcement with Avro or Protobuf

Expand orchestration with Airflow

Deploy using containers and cloud services

ğŸ‘¤ Author

Ajiri - Data Engineer

ğŸ’¬ Feedback

Contributions and suggestions are welcome! Open an issue or fork the repository to propose changes.


